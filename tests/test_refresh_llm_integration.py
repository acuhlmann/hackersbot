"""Integration test to verify the refresh endpoint actually calls the LLM and generates real summaries.

NOTE: These tests use mocks and temporary directories to avoid polluting the real
summaries/ and outputs/ directories with test data.
"""

import pytest
import json
import time
import urllib.request
import urllib.error
import tempfile
import shutil
from pathlib import Path
from datetime import datetime
from unittest.mock import patch, MagicMock, call

# Import the serve module
import sys
import os
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))


class TestRefreshLLMIntegration:
    """Test that refresh endpoint actually calls LLM and generates real summaries.
    
    NOTE: These tests verify that the refresh functionality calls the LLM correctly.
    They do NOT write to the real summaries/ directory - they use mocks that are
    patched to verify the calls are made correctly.
    """
    
    @pytest.fixture
    def temp_dirs(self):
        """Create temporary directories for test outputs."""
        temp_summaries = tempfile.mkdtemp(prefix="test_summaries_")
        temp_outputs = tempfile.mkdtemp(prefix="test_outputs_")
        yield {"summaries": Path(temp_summaries), "outputs": Path(temp_outputs)}
        # Cleanup
        shutil.rmtree(temp_summaries, ignore_errors=True)
        shutil.rmtree(temp_outputs, ignore_errors=True)
    
    def test_refresh_calls_llm_summarize(self):
        """Test that the summarizer agent calls LLM summarize method correctly.
        
        This is a unit test that verifies the LLM is called correctly by the
        summarizer agent, without starting a server or writing to real directories.
        """
        from src.models.llm_client import LLMClient
        from src.agents.summarizer_agent import SummarizerAgent
        
        # Create a mock LLM client
        mock_llm_client = MagicMock(spec=LLMClient)
        mock_llm_client.summarize.return_value = "This is a test summary generated by the LLM"
        mock_llm_client.get_filter_llm.return_value.invoke.return_value = json.dumps({
            "sentiment": "positive",
            "score": 0.8,
            "details": "Test details",
            "topics": ["AI", "tech"]
        })
        mock_llm_client.get_summarizer_llm.return_value.invoke.return_value = "Test summary"
        
        # Create test article
        test_article = {
            "id": "12345",
            "rank": 1,
            "title": "Unit Test Article",
            "url": "https://example.com/unit-test",
            "points": 100,
            "author": "tester",
            "time": "2 hours ago",
            "comment_count": 10,
            "comment_url": "https://news.ycombinator.com/item?id=12345",
            "comments": [
                {
                    "id": "c1",
                    "author": "user1",
                    "text": "This is a great article about technology and AI.",
                    "time": "1 hour ago",
                    "indent_level": 0
                }
            ],
            "content": "This is the article content about technology."
        }
        
        # Create summarizer with mock LLM
        summarizer = SummarizerAgent(llm_client=mock_llm_client)
        
        # Summarize the article
        result = summarizer.summarize_article(test_article, include_comments=True)
        
        # Verify that summarize was called
        assert mock_llm_client.summarize.called, "LLM summarize should have been called"
        
        # Check that article has summary
        assert "article_summary" in result, "Article should have an article_summary"
        assert result["article_summary"] == "This is a test summary generated by the LLM"
        
        # Verify summarize was called multiple times (for article and comments)
        summarize_calls = mock_llm_client.summarize.call_count
        assert summarize_calls >= 1, f"Expected summarize to be called at least once, got {summarize_calls}"
    
    def test_summarizer_generates_complete_summary(self):
        """Test that the summarizer generates complete summary data.
        
        This is a unit test that verifies the summarizer produces correct output
        structure without writing to any real directories.
        """
        from src.models.llm_client import LLMClient
        from src.agents.summarizer_agent import SummarizerAgent
        
        # Create a mock LLM client
        mock_llm_client = MagicMock(spec=LLMClient)
        mock_llm_client.summarize.return_value = "This article discusses important technology topics."
        mock_llm_client.get_filter_llm.return_value.invoke.return_value = json.dumps({
            "sentiment": "positive",
            "score": 0.75,
            "details": "Comments are generally positive",
            "topics": ["technology", "AI"]
        })
        mock_llm_client.get_summarizer_llm.return_value.invoke.return_value = "Summary"
        
        # Create test article with comments
        test_article = {
            "id": "67890",
            "rank": 1,
            "title": "Complete Summary Test Article",
            "url": "https://example.com/complete-test",
            "points": 200,
            "author": "tester",
            "time": "1 hour ago",
            "comment_count": 15,
            "comment_url": "https://news.ycombinator.com/item?id=67890",
            "comments": [
                {
                    "id": "c1",
                    "author": "commenter1",
                    "text": "This is a detailed comment about the article topic with enough content to be processed.",
                    "time": "30 minutes ago",
                    "indent_level": 0
                },
                {
                    "id": "c2",
                    "author": "commenter2",
                    "text": "Another substantial comment discussing the implications of the article.",
                    "time": "20 minutes ago",
                    "indent_level": 0
                }
            ],
            "content": "This is the full article content about technology and its impact."
        }
        
        # Create summarizer with mock LLM
        summarizer = SummarizerAgent(llm_client=mock_llm_client)
        
        # Summarize the article with comments
        result = summarizer.summarize_article(test_article, include_comments=True)
        
        # Verify article summary
        assert "article_summary" in result
        assert len(result["article_summary"]) > 10, "Article summary should be substantial"
        
        # Verify comment summary
        assert "comment_summary" in result
        assert result["comment_summary"] is not None
        
        # Verify sentiment analysis
        assert "comment_sentiment" in result
        assert result["comment_sentiment"] in ["positive", "negative", "neutral", "mixed"]
        
        # Verify topics
        assert "comment_topics" in result
        
        # Verify LLM was called
        assert mock_llm_client.summarize.called, "LLM summarize should have been called"

