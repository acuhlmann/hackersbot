"""Integration test to verify the refresh endpoint actually calls the LLM and generates real summaries."""

import pytest
import json
import time
import urllib.request
import urllib.error
from pathlib import Path
from datetime import datetime
from unittest.mock import patch, MagicMock, call

# Import the serve module
import sys
import os
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))
from serve import Handler, PROJECT_ROOT


class TestRefreshLLMIntegration:
    """Test that refresh endpoint actually calls LLM and generates real summaries."""
    
    @pytest.fixture
    def test_server(self):
        """Start a test server in a separate thread."""
        import http.server
        import socketserver
        import threading
        
        # Try to find an available port
        import socket
        port = None
        for test_port in range(9999, 10099):
            try:
                httpd = socketserver.TCPServer(("127.0.0.1", test_port), Handler)
                httpd.allow_reuse_address = True
                port = test_port
                break
            except OSError:
                continue
        
        if port is None:
            pytest.fail("Could not find an available port for test server")
        
        # Start server in a thread
        server_thread = threading.Thread(target=httpd.serve_forever)
        server_thread.daemon = True
        server_thread.start()
        
        # Wait for server to start
        time.sleep(0.5)
        
        yield f"http://127.0.0.1:{port}"
        
        # Cleanup
        httpd.shutdown()
        httpd.server_close()
    
    def test_refresh_calls_llm_summarize(self, test_server):
        """Test that refresh endpoint actually calls LLM summarize method."""
        from src.models.llm_client import LLMClient
        
        # Create a mock LLM client
        mock_llm_client = MagicMock(spec=LLMClient)
        mock_llm_client.summarize.return_value = "This is a test summary generated by the LLM"
        mock_llm_client.get_filter_llm.return_value.invoke.return_value = json.dumps({
            "sentiment": "positive",
            "score": 0.8,
            "details": "Test details",
            "topics": ["AI", "tech"]
        })
        mock_llm_client.get_summarizer_llm.return_value.invoke.return_value = "Test summary"
        
        # Mock the scraper to return test articles
        mock_articles = [
            {
                "id": "123",
                "rank": 1,
                "title": "Test Article from Hacker News",
                "url": "https://example.com/article",
                "points": 100,
                "author": "testuser",
                "time": "2 hours ago",
                "comment_count": 10,
                "comment_url": "https://news.ycombinator.com/item?id=123",
                "comments": [
                    {
                        "id": "c1",
                        "author": "user1",
                        "text": "This is a great article about technology and AI.",
                        "time": "1 hour ago",
                        "indent_level": 0
                    }
                ],
                "content": "This is the article content about technology."
            }
        ]
        
        with patch('src.models.llm_client.get_llm_client', return_value=mock_llm_client):
            with patch('src.agents.scraper_agent.ScraperAgent.scrape_articles_with_comments', return_value=mock_articles):
                with patch('src.agents.filter_agent.FilterAgent.batch_classify', side_effect=lambda x: x):
                    # Trigger refresh
                    url = f"{test_server}/api/refresh"
                    req = urllib.request.Request(url, method='POST')
                    req.add_header('Content-Type', 'application/json')
                    
                    try:
                        with urllib.request.urlopen(req, timeout=5) as response:
                            assert response.getcode() in (200, 409, 429)
                            data = json.loads(response.read().decode('utf-8'))
                            
                            # If refresh started, wait a bit for it to complete
                            if data.get('success'):
                                # Wait up to 30 seconds for the refresh to complete
                                max_wait = 30
                                start_time = time.time()
                                while time.time() - start_time < max_wait:
                                    time.sleep(1)
                                    # Check if summary was generated
                                    today = datetime.now().strftime("%Y-%m-%d")
                                    summary_file = PROJECT_ROOT / "summaries" / f"{today}_summary.json"
                                    if summary_file.exists():
                                        break
                    except urllib.error.HTTPError as e:
                        # Rate limit or conflict are acceptable
                        if e.code not in (409, 429):
                            raise
        
        # Verify that summarize was called
        assert mock_llm_client.summarize.called, "LLM summarize should have been called"
        
        # Check the calls - should have been called for article summary
        summarize_calls = mock_llm_client.summarize.call_count
        assert summarize_calls > 0, f"Expected summarize to be called at least once, but got {summarize_calls} calls"
    
    def test_refresh_generates_real_summary_file(self, test_server):
        """Test that refresh actually generates a summary file with real data."""
        # Clean up any existing today's summary
        today = datetime.now().strftime("%Y-%m-%d")
        summary_file = PROJECT_ROOT / "summaries" / f"{today}_summary.json"
        original_exists = summary_file.exists()
        original_content = None
        
        if original_exists:
            with open(summary_file, 'r') as f:
                original_content = f.read()
            summary_file.unlink()
        
        try:
            # Mock LLM to return real-looking summaries
            from src.models.llm_client import LLMClient
            
            mock_llm_client = MagicMock(spec=LLMClient)
            mock_llm_client.summarize.return_value = "This article discusses the latest developments in technology and AI."
            mock_llm_client.get_filter_llm.return_value.invoke.return_value = json.dumps({
                "sentiment": "positive",
                "score": 0.75,
                "details": "Comments are generally positive about the topic",
                "topics": ["technology", "AI", "innovation"]
            })
            mock_llm_client.get_summarizer_llm.return_value.invoke.return_value = "Summary text"
            
            # Mock scraper to return real-looking articles
            mock_articles = [
                {
                    "id": "123",
                    "rank": 1,
                    "title": "Real Hacker News Article Title",
                    "url": "https://example.com/real-article",
                    "points": 150,
                    "author": "realuser",
                    "time": "3 hours ago",
                    "comment_count": 25,
                    "comment_url": "https://news.ycombinator.com/item?id=123",
                    "comments": [
                        {
                            "id": "c1",
                            "author": "commenter1",
                            "text": "This is a real comment discussing the article in detail.",
                            "time": "2 hours ago",
                            "indent_level": 0
                        },
                        {
                            "id": "c2",
                            "author": "commenter2",
                            "text": "Another real comment with substantial content about the topic.",
                            "time": "1 hour ago",
                            "indent_level": 0
                        }
                    ],
                    "content": "This is the actual article content that would be scraped from the web."
                }
            ]
            
            with patch('src.models.llm_client.get_llm_client', return_value=mock_llm_client):
                with patch('src.agents.scraper_agent.ScraperAgent.scrape_articles_with_comments', return_value=mock_articles):
                    with patch('src.agents.filter_agent.FilterAgent.batch_classify', side_effect=lambda x: x):
                        # Trigger refresh
                        url = f"{test_server}/api/refresh"
                        req = urllib.request.Request(url, method='POST')
                        req.add_header('Content-Type', 'application/json')
                        
                        try:
                            with urllib.request.urlopen(req, timeout=5) as response:
                                data = json.loads(response.read().decode('utf-8'))
                                
                                # If refresh started, wait for it to complete
                                if data.get('success'):
                                    # Wait up to 30 seconds for the refresh to complete
                                    max_wait = 30
                                    start_time = time.time()
                                    summary_generated = False
                                    
                                    while time.time() - start_time < max_wait:
                                        time.sleep(1)
                                        if summary_file.exists():
                                            summary_generated = True
                                            break
                                    
                                    assert summary_generated, "Summary file should have been generated"
                                    
                                    # Verify the summary file contains real data
                                    with open(summary_file, 'r') as f:
                                        summary_data = json.load(f)
                                    
                                    # Check that it's not test data
                                    assert "Test Article" not in json.dumps(summary_data), "Summary should not contain test data"
                                    
                                    # Check that it has real article data
                                    assert "articles" in summary_data
                                    assert len(summary_data["articles"]) > 0
                                    
                                    first_article = summary_data["articles"][0]
                                    assert "title" in first_article
                                    assert "article_summary" in first_article, "Article should have a summary from LLM"
                                    assert first_article["article_summary"] != "", "Article summary should not be empty"
                                    
                                    # Verify the summary is from the LLM (not empty or placeholder)
                                    assert len(first_article["article_summary"]) > 20, "Summary should be substantial"
                                    
                                    # Verify LLM was actually called
                                    assert mock_llm_client.summarize.called, "LLM summarize should have been called"
                        except urllib.error.HTTPError as e:
                            if e.code not in (409, 429):
                                raise
        finally:
            # Restore original file if it existed
            if original_exists and original_content:
                with open(summary_file, 'w') as f:
                    f.write(original_content)
            elif not original_exists and summary_file.exists():
                summary_file.unlink()

